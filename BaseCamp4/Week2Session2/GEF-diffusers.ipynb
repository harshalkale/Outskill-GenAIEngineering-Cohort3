{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19b1e023",
   "metadata": {
    "id": "19b1e023",
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "! pip install datasets evaluate transformers diffusers accelerate ftfy pyarrow --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d874297",
   "metadata": {
    "id": "8d874297",
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from diffusers import StableDiffusionPipeline, StableDiffusionImg2ImgPipeline, StableDiffusionInpaintPipeline\n",
    "from PIL import Image\n",
    "import requests\n",
    "from io import BytesIO\n",
    "\n",
    "torch_device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd6ff25e",
   "metadata": {
    "id": "dd6ff25e"
   },
   "source": [
    "### Some examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0188dd5",
   "metadata": {
    "id": "d0188dd5",
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# -------------------------------------\n",
    "# 1. TEXT-TO-IMAGE GENERATION\n",
    "# -------------------------------------\n",
    "\n",
    "\n",
    "pipe = StableDiffusionPipeline.from_pretrained(\n",
    "    \"runwayml/stable-diffusion-v1-5\", torch_dtype=torch.float16\n",
    ").to(torch_device)\n",
    "\n",
    "# Example prompt\n",
    "prompt = \"Monkey D. Luffy from the anime 'One Piece' shaking hands with Prime Minister of India, Mr. Narendra Modi\"\n",
    "image = pipe(prompt, num_inference_steps=30, guidance_scale=7.5).images[0]\n",
    "\n",
    "display(image)\n",
    "\n",
    "\"\"\"\n",
    "üìù Parameters explained:\n",
    "- prompt: text description of the image\n",
    "- num_inference_steps: how many denoising steps (higher = better quality, slower)\n",
    "- guidance_scale: how strongly the prompt guides generation (7-8 is common; higher = more prompt fidelity, lower = more creativity)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d01c86f",
   "metadata": {
    "id": "0d01c86f",
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# -------------------------------------\n",
    "# 2. IMAGE-TO-IMAGE GENERATION\n",
    "# -------------------------------------\n",
    "\n",
    "img2img_pipe = StableDiffusionImg2ImgPipeline.from_pretrained(\n",
    "    \"runwayml/stable-diffusion-v1-5\", torch_dtype=torch.float16\n",
    ").to(torch_device)\n",
    "\n",
    "\n",
    "url = \"https://images.unsplash.com/photo-1480497490787-505ec076689f?q=80&w=2069&auto=format&fit=crop&ixlib=rb-4.1.0&ixid=M3wxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8fA%3D%3D\"\n",
    "init_image = Image.open(BytesIO(requests.get(url).content)).convert(\"RGB\").resize((512, 512))\n",
    "\n",
    "prompt = \"A futuristic city skyline painted on the mountain\"\n",
    "strength = 0.7  # how much noise to add: 0 = almost same as input, 1 = ignore input\n",
    "num_inference_steps = 40\n",
    "\n",
    "img2img = img2img_pipe(\n",
    "    prompt=prompt,\n",
    "    image=init_image,\n",
    "    strength=strength,\n",
    "    num_inference_steps=num_inference_steps,\n",
    "    guidance_scale=7.5\n",
    ").images[0]\n",
    "\n",
    "display(init_image)\n",
    "display(img2img)\n",
    "\n",
    "\"\"\"\n",
    "üìù Parameters explained:\n",
    "- image: input image you want to transform\n",
    "- strength: controls how much noise is added\n",
    "    - low strength (0.2-0.4): keeps input structure, small edits\n",
    "    - high strength (0.7-0.9): more creative, diverges from input\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
